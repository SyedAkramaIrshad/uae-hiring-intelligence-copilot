# App
APP_NAME=UAE Hiring Intelligence Copilot
APP_ENV=dev
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000

# LLM Provider: groq | openai | anthropic | ollama
LLM_VENDOR=groq
LLM_MODEL=groq/llama-3.1-8b-instant

# Keys (keep blank in repo)
GROQ_API_KEY=
OPENAI_API_KEY=
ANTHROPIC_API_KEY=

# Optional endpoints
GROQ_BASE_URL=https://api.groq.com/openai/v1
OPENAI_BASE_URL=https://api.openai.com/v1
OLLAMA_BASE_URL=http://localhost:11434

# Fallback mode (if no key, app automatically uses deterministic rule-based mode)
RULE_BASED_DEFAULT=true

# Throughput controls (set to 1 for strict sequential; raise for higher throughput)
CANDIDATE_BATCH_SIZE=1
CANDIDATE_BATCH_PAUSE_SECONDS=1.5
LLM_CALL_PAUSE_SECONDS=5.0

# Retry controls (exponential backoff)
LLM_RETRY_ATTEMPTS=3
LLM_RETRY_BASE_SECONDS=2.0
LLM_RETRY_MAX_SECONDS=12.0

# Token controls (smaller = cheaper + fewer 429s)
LLM_JD_CHARS=700
LLM_CV_CHARS=700
LLM_MAX_TOKENS=500
